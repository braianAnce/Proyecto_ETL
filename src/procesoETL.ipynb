{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from funciones.ipynb\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Importacion de funciones.\n",
    "import import_ipynb\n",
    "import funciones as f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta de la carpeta que almacena todos los archivos CSV\n",
    "\n",
    "dir_path = f\"{os.path.dirname(os.getcwd())}/archivos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se busca extraer los archivos .csv guardados en la carpeta archivos.\n",
    "\n",
    "df_factors = pd.read_csv(f'{dir_path}/factors.csv')\n",
    "df_intensity = pd.read_csv(f'{dir_path}/intensity.csv')\n",
    "df_regional = pd.read_csv(f'{dir_path}/regional.csv')\n",
    "df_date = pd.read_csv(f'{dir_path}/date.csv')\n",
    "df_generation = pd.read_csv(f'{dir_path}/generation.csv')\n",
    "df_regions = pd.read_csv(f'{dir_path}/regions.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se cambia el tipo de dato de la columna \"fuels\" a string.\n",
    "\n",
    "df_factors = df_factors.rename(columns = {'Fuels':'fuels'})\n",
    "df_factors['fuels'] = df_factors['fuels'].astype(\"string\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cambiar a tipo de datos correctos.\n",
    "df_intensity['from'] = pd.to_datetime(df_intensity['from'])\n",
    "df_intensity['intensity.index'] = df_intensity['intensity.index'].astype('string')\n",
    "\n",
    "# Eliminar columna to\n",
    "df_intensity = df_intensity.drop(columns= ['to'])\n",
    "\n",
    "# Crear columna a√±o, mes, dia y hora\n",
    "df_intensity['hour'] = df_intensity['from'].dt.time\n",
    "df_intensity['month'] = df_intensity['from'].dt.month\n",
    "df_intensity['day'] = df_intensity['from'].dt.day\n",
    "df_intensity['year'] = df_intensity['from'].dt.year\n",
    "\n",
    "# Filtrar los registros obtenidos por hora\n",
    "df_intensity = df_intensity[df_intensity['hour'].apply(lambda x: x.minute == 0)]\n",
    "\n",
    "# Reordenar ubicacion de columnas\n",
    "df_intensity = df_intensity.reindex(columns=['from','year','month','day', 'hour', 'intensity.forecast', 'intensity.actual', 'intensity.index'])\n",
    "\n",
    "#renombrar columna from a date\n",
    "df_intensity = df_intensity.rename(columns = {\n",
    "    'from':'col_date',\n",
    "    'intensity.forecast': 'intensity_forecast',\n",
    "    'intensity.actual':'intensity_actual',\n",
    "    'intensity.index':'intensity_index'})\n",
    "\n",
    "# Resetear indices\n",
    "df_intensity.reset_index(drop=True, inplace= True)\n",
    "\n",
    "# Cambiar tipo de dato\n",
    "df_intensity['hour']= df_intensity['hour'].astype(str).str.split(':').str[0].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificar formato de fecha de la columna date, se busca eliminar el '+00:00' sin cambiar de tipo de dato.\n",
    "df_intensity['col_date'] = pd.to_datetime(df_intensity['col_date'].dt.strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambio de tipo de dato de la columna shortname a string.\n",
    "df_regions['shortname'] = df_regions['shortname'].astype(\"string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificar formato de fecha de la columna date, se busca eliminar el '+00:00' sin cambiar de tipo de dato.\n",
    "df_date['date'] = pd.to_datetime(df_date['date']).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "# Cambiar tipo de datos de la columnas: year, month, day, hour y cod_date.\n",
    "# Reordenar el orden de las columnas.\n",
    "# Se vuelve a convertir a la columna date en tipo de dato datetime, debido a que la funcion strftime retorna un tipo de dato string.\n",
    "df_date['year']= df_date['year'].astype(int)\n",
    "df_date['month']= df_date['month'].astype(int)\n",
    "df_date['day']= df_date['day'].astype(int)\n",
    "df_date['hour']= df_date['hour'].astype(str).str.split(':').str[0].astype(int)\n",
    "df_date['cod_date'] = df_date['cod_date'].astype(\"string\")\n",
    "df_date['date'] = pd.to_datetime(df_date['date'])\n",
    "\n",
    "#Renombrar columna\n",
    "df_date.rename(columns = {'date': 'col_date'}, inplace= True)\n",
    "\n",
    "df_date = df_date.reindex(\n",
    "    columns=['col_date','year','month','day', 'hour', 'cod_date']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversion de tipo de datos.\n",
    "df_generation['fuel'] = df_generation['fuel'].astype(\"string\")\n",
    "df_generation['cod_date'] = df_generation['cod_date'].astype(\"string\")\n",
    "df_generation['regionid'] = df_generation['regionid'].astype(int)\n",
    "\n",
    "#Reordenar columnas.\n",
    "df_generation = df_generation.reindex(\n",
    "    columns=['regionid','cod_date','fuel','perc']\n",
    "    )\n",
    "\n",
    "#Convertir las primeras letras de los combustibles de la columna fuel en mayusculas.\n",
    "df_generation ['fuel'] = df_generation['fuel'].str.capitalize()\n",
    "\n",
    "#renombrar columna regionid a region_id\n",
    "df_generation = df_generation.rename(columns = {'regionid':'region_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_regional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar columnas\n",
    "df_regional.drop(columns = ['dnoregion', 'shortname', 'generationmix'], inplace = True)\n",
    "\n",
    "# Reordenar columnas.\n",
    "df_regional = df_regional.reindex(\n",
    "    columns=['region_id','cod_date','intensity.forecast','intensity.index']\n",
    "    )\n",
    "\n",
    "# Cambiar tipo de datos.\n",
    "df_regional['cod_date'] = df_regional['cod_date'].astype(\"string\")\n",
    "df_regional['region_id'] = df_regional['region_id'].astype(int)\n",
    "df_regional['intensity.forecast'] = df_regional['intensity.forecast'].astype(int)\n",
    "df_regional['intensity.index'] = df_regional['intensity.index'].astype('string')\n",
    "\n",
    "# Renombrar columnas\n",
    "df_regional.rename(columns={'intensity.forecast':'intensity_forecast',\n",
    "                            'intensity.index':'intensity_index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Localizar valores nulos en todos los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATAFRAME: df_intensity\n",
      "\n",
      "col_date              0\n",
      "year                  0\n",
      "month                 0\n",
      "day                   0\n",
      "hour                  0\n",
      "intensity_forecast    0\n",
      "intensity_actual      0\n",
      "intensity_index       0\n",
      "dtype: int64\n",
      "-------------------\n",
      "\n",
      "DATAFRAME: df_factors\n",
      "\n",
      "fuels    0\n",
      "value    0\n",
      "dtype: int64\n",
      "-------------------\n",
      "\n",
      "DATAFRAME: df_date\n",
      "\n",
      "col_date    0\n",
      "year        0\n",
      "month       0\n",
      "day         0\n",
      "hour        0\n",
      "cod_date    0\n",
      "dtype: int64\n",
      "-------------------\n",
      "\n",
      "DATAFRAME: df_generation\n",
      "\n",
      "region_id    0\n",
      "cod_date     0\n",
      "fuel         0\n",
      "perc         0\n",
      "dtype: int64\n",
      "-------------------\n",
      "\n",
      "DATAFRAME: df_regional\n",
      "\n",
      "region_id             0\n",
      "cod_date              0\n",
      "intensity_forecast    0\n",
      "intensity_index       0\n",
      "dtype: int64\n",
      "-------------------\n",
      "\n",
      "DATAFRAME: df_regions\n",
      "\n",
      "region_id    0\n",
      "shortname    0\n",
      "dtype: int64\n",
      "-------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Localizar valores nulos en todos los dataframes\n",
    "\n",
    "lista_dfs = [df_intensity, df_factors, df_date, df_generation, df_regional, df_regions]\n",
    "nombre_dfs = ['df_intensity', 'df_factors', 'df_date', 'df_generation', 'df_regional', 'df_regions']\n",
    "i=0\n",
    "for df in lista_dfs:\n",
    "  suma = df.isnull().sum()\n",
    "  print(f'DATAFRAME: {nombre_dfs[i]}')\n",
    "  print('')\n",
    "  print(suma)\n",
    "  print('-------------------')\n",
    "  print('')\n",
    "  i=i+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establecer relacion entre dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relacion entre DF: generation, regions y date.\n",
    "#Se busca crear un DF que almacene los percentiles de los fines de semana (sabados y domingos.)\n",
    "\n",
    "df_perc_wknd= pd.merge(pd.merge(df_generation,df_regions, on= 'region_id', how = 'inner'),\n",
    "                       df_date, on= 'cod_date', how = 'inner')\n",
    "\n",
    "#Crear columna dias de semana\n",
    "df_perc_wknd['day_name'] = df_perc_wknd['col_date'].dt.day_name().astype(\"string\")\n",
    "\n",
    "# Obtener registros de percentiles de los fin de semanas.\n",
    "dias = ['Saturday', 'Sunday']\n",
    "filtro = df_perc_wknd['day_name'].isin(dias)\n",
    "df_perc_wknd = df_perc_wknd[filtro].reset_index(drop= True)\n",
    "\n",
    "#Reordenar columnas\n",
    "df_perc_wknd = df_perc_wknd.reindex(\n",
    "    columns=['region_id','cod_date', 'year','month','day', 'hour', 'day_name', 'fuel', 'perc']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se realiza la carga de datos a una base de datos postgresql. Se hace uso de la funcion connect_to_postgres para realizar la conexion.\n",
    "conn_path = f\"{os.path.dirname(os.getcwd())}/credenciales/config.ini\"\n",
    "engine = f.connect_to_postgres(conn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x1fc063bb490>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Truncar tablas.\n",
    "# El objetivo de truncar tablas es evitar la duplicacion de datos.\n",
    "# Proximamente: crear un Procedimiento Almacenado que lo evite.\n",
    "\n",
    "engine.execute('truncate table ba_regions')\n",
    "engine.execute('truncate table ba_intensity_national')\n",
    "engine.execute('truncate table ba_factors')\n",
    "engine.execute('truncate table ba_time')\n",
    "engine.execute('truncate table ba_regional')\n",
    "engine.execute('truncate table ba_generation')\n",
    "engine.execute('truncate table ba_perc_weekend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regions.to_sql('ba_regions',\n",
    "                  engine,\n",
    "                  method=\"multi\", chunksize=1000,\n",
    "                  if_exists= 'append',\n",
    "                  index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intensity.to_sql('ba_intensity_national',\n",
    "                  engine,\n",
    "                  method=\"multi\", chunksize=1000,\n",
    "                  if_exists= 'append',\n",
    "                  index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_factors.to_sql('ba_factors',\n",
    "                  engine,\n",
    "                  method=\"multi\", chunksize=1000,\n",
    "                  if_exists= 'append',\n",
    "                  index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date.to_sql('ba_time',\n",
    "                  engine,\n",
    "                  method=\"multi\", chunksize=1000,\n",
    "                  if_exists= 'append',\n",
    "                  index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regional.to_sql('ba_regional',\n",
    "                  engine,\n",
    "                  method=\"multi\", chunksize=5000,\n",
    "                  if_exists= 'append',\n",
    "                  index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generation.to_sql('ba_generation',\n",
    "                  engine,\n",
    "                  method=\"multi\", chunksize=5000,\n",
    "                  if_exists= 'append',\n",
    "                  index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perc_wknd.to_sql('ba_perc_weekend',\n",
    "                  engine,\n",
    "                  method=\"multi\", chunksize=5000,\n",
    "                  if_exists= 'append',\n",
    "                  index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
